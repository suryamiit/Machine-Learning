{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(583, 11)\n",
      "(579, 11)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\suryanarayana\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:433: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LR: 0.6896551724137931\n",
      "NB: 0.6896551724137931\n",
      "Poly kernel SVM Score :  0.6896551724137931\n",
      "AdaBoost with  Logistic Regression , classifier score: 0.7183908045977011\n",
      "Confusion Matrix of  Logistic Regression  with AdaBoost:\n",
      "[[  2  48]\n",
      " [  1 123]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.67      0.04      0.08        50\n",
      "           1       0.72      0.99      0.83       124\n",
      "\n",
      "   micro avg       0.72      0.72      0.72       174\n",
      "   macro avg       0.69      0.52      0.45       174\n",
      "weighted avg       0.70      0.72      0.62       174\n",
      "\n",
      "AdaBoost with  Na誰ve Bayes , classifier score: 0.5862068965517241\n",
      "Confusion Matrix of  Na誰ve Bayes  with AdaBoost:\n",
      "[[49  1]\n",
      " [71 53]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.41      0.98      0.58        50\n",
      "           1       0.98      0.43      0.60       124\n",
      "\n",
      "   micro avg       0.59      0.59      0.59       174\n",
      "   macro avg       0.69      0.70      0.59       174\n",
      "weighted avg       0.82      0.59      0.59       174\n",
      "\n",
      "AdaBoost with  Polynomial SVM , classifier score: 0.5229885057471264\n",
      "Confusion Matrix of  Polynomial SVM  with AdaBoost:\n",
      "[[ 8 42]\n",
      " [41 83]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.16      0.16      0.16        50\n",
      "           1       0.66      0.67      0.67       124\n",
      "\n",
      "   micro avg       0.52      0.52      0.52       174\n",
      "   macro avg       0.41      0.41      0.41       174\n",
      "weighted avg       0.52      0.52      0.52       174\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\suryanarayana\\Anaconda3\\lib\\site-packages\\sklearn\\svm\\base.py:196: FutureWarning: The default value of gamma will change from 'auto' to 'scale' in version 0.22 to account better for unscaled features. Set gamma explicitly to 'auto' or 'scale' to avoid this warning.\n",
      "  \"avoid this warning.\", FutureWarning)\n",
      "C:\\Users\\suryanarayana\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:433: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "C:\\Users\\suryanarayana\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:433: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "C:\\Users\\suryanarayana\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:433: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "C:\\Users\\suryanarayana\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:433: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "C:\\Users\\suryanarayana\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:433: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "C:\\Users\\suryanarayana\\Anaconda3\\lib\\site-packages\\sklearn\\svm\\base.py:196: FutureWarning: The default value of gamma will change from 'auto' to 'scale' in version 0.22 to account better for unscaled features. Set gamma explicitly to 'auto' or 'scale' to avoid this warning.\n",
      "  \"avoid this warning.\", FutureWarning)\n",
      "C:\\Users\\suryanarayana\\Anaconda3\\lib\\site-packages\\sklearn\\svm\\base.py:196: FutureWarning: The default value of gamma will change from 'auto' to 'scale' in version 0.22 to account better for unscaled features. Set gamma explicitly to 'auto' or 'scale' to avoid this warning.\n",
      "  \"avoid this warning.\", FutureWarning)\n",
      "C:\\Users\\suryanarayana\\Anaconda3\\lib\\site-packages\\sklearn\\ensemble\\forest.py:246: FutureWarning: The default value of n_estimators will change from 10 in version 0.20 to 100 in 0.22.\n",
      "  \"10 in version 0.20 to 100 in 0.22.\", FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RDF classifier Score: 0.6839080459770115\n",
      "RDF with GridSearchCV classifier Score: 0.6839080459770115\n",
      "XGBoost Classifier Score: 0.6839080459770115\n",
      "Logistic Regression without AdaBoost  Score :  0.6896551724137931\n",
      "Confusion Matrix of  Logistic Regression without AdaBoost  :\n",
      "[[  5  45]\n",
      " [  9 115]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.36      0.10      0.16        50\n",
      "           1       0.72      0.93      0.81       124\n",
      "\n",
      "   micro avg       0.69      0.69      0.69       174\n",
      "   macro avg       0.54      0.51      0.48       174\n",
      "weighted avg       0.61      0.69      0.62       174\n",
      "\n",
      "Na誰ve Bayes without AdaBoost  Score :  0.5862068965517241\n",
      "Confusion Matrix of  Na誰ve Bayes without AdaBoost  :\n",
      "[[49  1]\n",
      " [71 53]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.41      0.98      0.58        50\n",
      "           1       0.98      0.43      0.60       124\n",
      "\n",
      "   micro avg       0.59      0.59      0.59       174\n",
      "   macro avg       0.69      0.70      0.59       174\n",
      "weighted avg       0.82      0.59      0.59       174\n",
      "\n",
      "Polynomial SVM without AdaBoost  Score :  0.5229885057471264\n",
      "Confusion Matrix of  Polynomial SVM without AdaBoost  :\n",
      "[[ 8 42]\n",
      " [41 83]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.16      0.16      0.16        50\n",
      "           1       0.66      0.67      0.67       124\n",
      "\n",
      "   micro avg       0.52      0.52      0.52       174\n",
      "   macro avg       0.41      0.41      0.41       174\n",
      "weighted avg       0.52      0.52      0.52       174\n",
      "\n",
      "RDF without GridSearchCV  Score :  0.6839080459770115\n",
      "Confusion Matrix of  RDF without GridSearchCV  :\n",
      "[[ 15  35]\n",
      " [ 20 104]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.43      0.30      0.35        50\n",
      "           1       0.75      0.84      0.79       124\n",
      "\n",
      "   micro avg       0.68      0.68      0.68       174\n",
      "   macro avg       0.59      0.57      0.57       174\n",
      "weighted avg       0.66      0.68      0.67       174\n",
      "\n",
      "RDF with GridSearchCV  Score :  0.6839080459770115\n",
      "Confusion Matrix of  RDF with GridSearchCV  :\n",
      "[[ 10  40]\n",
      " [ 15 109]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.40      0.20      0.27        50\n",
      "           1       0.73      0.88      0.80       124\n",
      "\n",
      "   micro avg       0.68      0.68      0.68       174\n",
      "   macro avg       0.57      0.54      0.53       174\n",
      "weighted avg       0.64      0.68      0.65       174\n",
      "\n",
      "XGBoost  Score :  0.6839080459770115\n",
      "Confusion Matrix of  XGBoost  :\n",
      "[[ 12  38]\n",
      " [ 17 107]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.41      0.24      0.30        50\n",
      "           1       0.74      0.86      0.80       124\n",
      "\n",
      "   micro avg       0.68      0.68      0.68       174\n",
      "   macro avg       0.58      0.55      0.55       174\n",
      "weighted avg       0.64      0.68      0.65       174\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "import pandas as pd\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "from sklearn.svm import SVC\n",
    "\n",
    "from sklearn.metrics import confusion_matrix\n",
    "\n",
    "from sklearn.metrics import classification_report\n",
    "\n",
    "from sklearn.ensemble import AdaBoostClassifier\n",
    "\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "\n",
    "from sklearn import metrics\n",
    "\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "from xgboost import XGBClassifier\n",
    "\n",
    "\n",
    "\n",
    "#Load the dataset\n",
    "\n",
    "df = pd.read_csv('liver_disease_.csv')\n",
    "\n",
    "print(df.shape)\n",
    "\n",
    "\n",
    "\n",
    "df= df.dropna()\n",
    "\n",
    "print(df.shape)\n",
    "\n",
    "\n",
    "\n",
    "df[\"Gender\"] = df[\"Gender\"].astype('category').cat.codes\n",
    "\n",
    "df[\"Dataset\"] = np.where(df['Dataset'].str.contains('Yes'), 1, 0)\n",
    "\n",
    "\n",
    "\n",
    "#Let's create numpy arrays for features and target\n",
    "\n",
    "X = df.drop('Dataset',axis=1).values\n",
    "\n",
    "y = df['Dataset'].values\n",
    "\n",
    "\n",
    "\n",
    "#Split the dataset into train and test with stratification\n",
    "\n",
    "X_train,X_test,y_train,y_test = train_test_split(X,y,test_size=0.3,random_state=42, stratify=y)\n",
    "\n",
    "\n",
    "\n",
    "# a) Model1 = Logistic Regression, Model2 = Na誰ve Bayes and Model3 = Polynomial SVM\n",
    "\n",
    "model1=LogisticRegression()\n",
    "\n",
    "model1.fit(X_train,y_train)\n",
    "\n",
    "mod1_y_pred=model1.predict(X_test)\n",
    "\n",
    "print(\"LR:\",accuracy_score(y_test, mod1_y_pred))\n",
    "\n",
    "\n",
    "\n",
    "model2= GaussianNB()\n",
    "\n",
    "model2.fit(X_train,y_train)\n",
    "\n",
    "mod2_y_pred=model1.predict(X_test)\n",
    "\n",
    "print(\"NB:\",accuracy_score(y_test, mod2_y_pred))\n",
    "\n",
    "\n",
    "\n",
    "model3 = SVC(kernel='poly', degree=8)\n",
    "\n",
    "model3.fit(X_train, y_train)\n",
    "\n",
    "mod3_y_pred=model1.predict(X_test)\n",
    "\n",
    "print(\"Poly kernel SVM Score : \", accuracy_score(y_test, mod3_y_pred))\n",
    "\n",
    "\n",
    "\n",
    "# a) Model1 = Logistic Regression, Model2 = Na誰ve Bayes and Model3 = Polynomial SVM with AdaBoostClassifier\n",
    "\n",
    "def adaReport(classifierName, classifier):\n",
    "\n",
    "    ada = AdaBoostClassifier(classifier, algorithm='SAMME')\n",
    "\n",
    "    ada.fit(X_train, y_train)\n",
    "\n",
    "    y_pred=ada.predict(X_test)\n",
    "\n",
    "    print(\"AdaBoost with \",classifierName, \", classifier score:\",accuracy_score(y_test, y_pred))\n",
    "\n",
    "    print(\"Confusion Matrix of \", classifierName, \" with AdaBoost:\")\n",
    "\n",
    "    print(confusion_matrix(y_test,y_pred))\n",
    "\n",
    "    print(classification_report(y_test,y_pred))\n",
    "\n",
    "\n",
    "\n",
    "adaReport(\"Logistic Regression\", model1)\n",
    "\n",
    "adaReport(\"Na誰ve Bayes\", model2)\n",
    "\n",
    "adaReport(\"Polynomial SVM\", model3)\n",
    "\n",
    "\n",
    "\n",
    "# b)\tImplement Random Forest\n",
    "\n",
    "rdf=RandomForestClassifier()\n",
    "\n",
    "rdf.fit(X_train,y_train)\n",
    "\n",
    "y_pred=rdf.predict(X_test)\n",
    "\n",
    "print(\"RDF classifier Score:\",accuracy_score(y_test, y_pred))\n",
    "\n",
    "\n",
    "\n",
    "# b)\tImplement Random Forest (with Grid Search CV)\n",
    "\n",
    "rfc = RandomForestClassifier(n_jobs=-1,max_features= 'sqrt' ,n_estimators=50, oob_score = True)\n",
    "\n",
    "param_grid = {\n",
    "\n",
    "    'n_estimators': [50],\n",
    "\n",
    "    'max_features': ['auto', 'sqrt', 'log2']\n",
    "\n",
    "}\n",
    "\n",
    "\n",
    "\n",
    "CV_rfc = GridSearchCV(estimator=rfc, param_grid=param_grid, cv= 5)\n",
    "\n",
    "CV_rfc.fit(X_train,y_train)\n",
    "\n",
    "y_pred=CV_rfc.predict(X_test)\n",
    "\n",
    "print(\"RDF with GridSearchCV classifier Score:\",accuracy_score(y_test, y_pred))\n",
    "\n",
    "\n",
    "\n",
    "# c)\tImplement XG Boost\n",
    "\n",
    "\n",
    "\n",
    "model = XGBClassifier()\n",
    "\n",
    "model.fit(X_train, y_train)\n",
    "\n",
    "y_pred = model.predict(X_test)\n",
    "\n",
    "print(\"XGBoost Classifier Score:\",accuracy_score(y_test, y_pred))\n",
    "\n",
    "\n",
    "\n",
    "# d)\tCompare accuracy measures (Precision/Recall/F1/CM)\n",
    "\n",
    "def report(classifierName, classifier ):\n",
    "\n",
    "    y_pred_ = classifier.predict(X_test)\n",
    "\n",
    "    print (classifierName, \" Score : \",classifier.score(X_test,y_test))\n",
    "\n",
    "    print(\"Confusion Matrix of \", classifierName, \" :\" )\n",
    "\n",
    "    print(confusion_matrix(y_test,y_pred_))\n",
    "\n",
    "    print(classification_report(y_test,y_pred_))\n",
    "\n",
    "\n",
    "\n",
    "report(\"Logistic Regression without AdaBoost\", model1)\n",
    "\n",
    "report(\"Na誰ve Bayes without AdaBoost\", model2)\n",
    "\n",
    "report(\"Polynomial SVM without AdaBoost\", model3)\n",
    "\n",
    "report(\"RDF without GridSearchCV\", rdf)\n",
    "\n",
    "report(\"RDF with GridSearchCV\", CV_rfc)\n",
    "\n",
    "report(\"XGBoost\", model)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
